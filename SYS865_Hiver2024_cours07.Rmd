---
title: "SYS865 Inférence statistique avec programmation R"
author: "Ornwipa Thamsuwan"
date: "21 février 2024"
# date: "`r format(Sys.time(), '%d-%m-%Y')`"
output:
  beamer_presentation: 
    slide_level: 2
    theme: "Goettingen"
    colortheme: "crane"
    fonttheme: "structurebold"
header-includes:
- \setbeamertemplate{navigation symbols}{}
- \setbeamertemplate{footline}[page number]
---

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

# Recap

- Objectifs de l'étude
- Formulation d'hypothèse
- Collecte des données : plan d'échantillonage
- Analyse des données : **choix du test statistique**
- Décision et interprétation

\pause
\textcolor{brown}{Comment choisir le test statistique ?}

## Inférence statistique

**Les conditions pour les choix du test**

- Test de normalité (Shapiro-Wilk)
\pause
- Test de homogénéité des variances
  - Test F pour les données \textcolor{brown}{normalement distribuées}
  - Test de Levene

\pause
**Les paramètres à étudier**

- La moyenne d'un échantillon ou la différence entre deux échantillons appariés
  - Test t avec `paired=TRUE` pour les données \textcolor{brown}{normalement distribuées}
  - Test de Wilcoxon pour échantillons appariés

\pause
- Les moyennes des deux échantillons indépendants
  - Test t par défault pour les données \textcolor{brown}{normalement distribuées}
  - Test de rang somme de Wilcoxon

## Erreur statistique (retour)

Erreur type I (\(\alpha\)) : Rejeter \(H_0\) quand \(H_0\) est vraie.

Erreur type II (\(\beta\)) : Ne pas rejeter \(H_0\) quand \(H_0\) est fausse.

```{r, echo=FALSE}
data <- read.csv("diabetes.csv")
filtered_data <- subset(data, Glucose > 0)

# Calculate mean and standard deviation for each Outcome group
mean_glucose_0 <- mean(subset(filtered_data, Outcome == 0)$Glucose, na.rm = TRUE)
sd_glucose_0 <- sd(subset(filtered_data, Outcome == 0)$Glucose, na.rm = TRUE)

mean_glucose_1 <- mean(subset(filtered_data, Outcome == 1)$Glucose, na.rm = TRUE)
sd_glucose_1 <- sd(subset(filtered_data, Outcome == 1)$Glucose, na.rm = TRUE)

# Define a sequence of glucose values for plotting
glucose_range <- seq(min(filtered_data$Glucose, na.rm = TRUE), max(filtered_data$Glucose, na.rm = TRUE), length.out = 200)

# Calculate normal distribution values for each group
normal_values_0 <- dnorm(glucose_range, mean = mean_glucose_0, sd = sd_glucose_0)
normal_values_1 <- dnorm(glucose_range, mean = mean_glucose_1, sd = sd_glucose_1)

# Plot the normal probability distributions
plot(glucose_range, normal_values_0, type = 'l', col = 'blue', lwd = 2, 
     main = 'Normal Probability Distributions of Glucose by Outcome', 
     xlab = 'Concentration de Glucose Plasmatique à 2h (GTIT) [mg/dL]', 
     ylab = 'Density', ylim = c(0, max(normal_values_0, normal_values_1)))
lines(glucose_range, normal_values_1, col = 'red', lwd = 2)

# Add a vertical line at x=140
abline(v = 140, col = "black", lwd = 2, lty = 2)

# Highlight the area under the blue curve to the right of x=140 (Type I error area for Outcome 0)
x_area <- glucose_range[glucose_range > 140]
y_area <- dnorm(x_area, mean = mean_glucose_0, sd = sd_glucose_0)
polygon(c(140, x_area, max(glucose_range)), c(0, y_area, 0), col = "lightblue", border = NA)

# Highlight the area under the red curve to the left of x=140 (Type II error area for Outcome 1)
x_area <- glucose_range[glucose_range < 140]
y_area <- dnorm(x_area, mean = mean_glucose_1, sd = sd_glucose_1)
polygon(c(min(glucose_range), x_area, 140), c(0, y_area, 0), col = "lightcoral", border = NA)

# Add a legend
legend("topright", legend = c("Outcome 0", "Outcome 1", "Erreur type I","Erreur Type II"), 
       col = c("blue", "red", "lightblue", "lightcoral"), lty = 1, lwd = 2, bty = "n")
```

## Erreur statistique (retour)

"Power" (\(1-\beta\)) : Correctement rejeter \(H_0\) quand \(H_0\) est fausse, ou quand \(H_1\) est vraie. 

```{r, echo=FALSE}
# Plot the normal probability distributions
plot(glucose_range, normal_values_0, type = 'l', col = 'blue', lwd = 2, 
     main = 'Normal Probability Distributions of Glucose by Outcome', 
     xlab = 'Concentration de Glucose Plasmatique à 2h (GTIT) [mg/dL]', 
     ylab = 'Density', ylim = c(0, max(normal_values_0, normal_values_1)))
lines(glucose_range, normal_values_1, col = 'red', lwd = 2)

# Add a vertical line at x=140
abline(v = 140, col = "black", lwd = 2, lty = 2)

# Highlight the area under the red curve to the right of x=140
x_area <- glucose_range[glucose_range > 140]
y_area <- dnorm(x_area, mean = mean_glucose_1, sd = sd_glucose_1)
polygon(c(140, x_area, max(glucose_range)), c(0, y_area, 0), col = "turquoise", border = NA)

# Add a legend
legend("topright", legend = c("Outcome 0", "Outcome 1", "Power = 1 - Erreur Type II"), 
       col = c("blue", "red", "turquoise"), lty = 1, lwd = 2, bty = "n")
```

# Puissance statistique

![Tableau de contingence](Slide-images\contingencytable.jpg){width=70%, height=70%}

## Calcul de la puissance statistique

1. Définir les hypothèses et décider du type de test t

- **Hypothèse nulle (\(H_0\))**: Il n'existe aucune différence entre les groupes que vous comparez.
- **Hypothèse alternative (\(H_1\))**: Il existe une différence significative.
- Décidez si l'on réalise un test t unilatéral (si l'on attend une différence dans une direction spécifique) ou bilatéral (en cas où les différences dans les deux directions sont pertinentes).

\pause

2. Choisir un niveau de signification (\(\alpha\)). Typiquement, \(\alpha = 0.05\).

\pause

3. Supposer que la taille de l'échantillon (n) pour chaque groupe est donnée.

## Calcul de puissance statistique

4. Déterminer la taille de l'effet

La taille de l'effet de Cohen's d est définie comme:

\[ d = \frac{\mu_1 - \mu_2}{SD_{\text{poolisée}}} \]

Où \(\mu_1\) et \(\mu_2\) sont les moyennes des deux groupes, et \(SD_{\text{poolisée}}\) est l'écart-type poolisé, calculé en fonction des écarts-types des deux groupes.

\pause

\[ SD_{\text{poolisée}} = \sqrt{\frac{(n_1 - 1) \times SD_1^2 + (n_2 - 1) \times SD_2^2}{n_1 + n_2 - 2}} \]

Où \( n_1 \) et \( n_2 \) sont les tailles d'échantillon des deux groupes, et \( SD_1 \) et \( SD_2 \) sont les déviations standard des deux groupes.

## Calcul de la puissance statistique

5. Calculer ou estimer la puissance (\(1-\beta\)) avec R

\pause
Paramètres
```{r}
effect_size <- 0.5
n1 <- 30
n2 <- 40
alpha <- 0.05
```

\pause
Calcul des degrés de liberté
```{r}
df <- n1 + n2 - 2
df
```

## Calcul de la puissance statistique

Calcul de la valeur t critique
```{r}
t_critical <- qt(1 - alpha / 2, df)
t_critical
```

La fonction `qt()` fournit le quantile de la distribution t.

## Calcul de la puissance statistique

Calcul du paramètre de non-centralité
```{r}
ncp <- effect_size * sqrt((n1 * n2) / (n1 + n2))
ncp
```

Le paramètre de non-centralité **`ncp`** représente à quel point l'effet réel est éloigné de l'hypothèse nulle dans le contexte d'une hypothèse alternative spécifique.

Le **`ncp`** est ajusté pour les tailles d'échantillon inégales en utilisant la formule suivante :
\[ ncp = \text{effect size} \times \sqrt{\frac{n_1 \times n_2}{n_1 + n_2}} \]

## Calcul de la puissance statistique

Calcul de la puissance
```{r}
power <- 1 - pt(t_critical, df, ncp)
power
```

La fonction `pt()` donne la fonction de répartition (c'est-à-dire, la probabilité cumulée) pour la distribution t.

## Facteurs importants

**Taille d'échantillon**

```{r}
n1 <- 120 # augmenté de 30
n2 <- 120 # augmenté de 40
```
\pause
Tout en fixant d'autres paramètres, la puissance augmente à
```{r, echo=FALSE}
effect_size <- 0.5
df <- n1 + n2 - 2
t_critical <- qt(1 - alpha / 2, df)
ncp <- effect_size * sqrt((n1 * n2) / (n1 + n2))
power <- 1 - pt(t_critical, df, ncp)
power
```
\pause

**Taille d'effet**

```{r}
effect_size <- 1 # augmenté de 0.5
```
\pause
Tout en fixant d'autres paramètres, la puissance augmente à
```{r, echo=FALSE}
n1 <- 30
n2 <- 40
df <- n1 + n2 - 2
t_critical <- qt(1 - alpha / 2, df)
ncp <- effect_size * sqrt((n1 * n2) / (n1 + n2))
power <- 1 - pt(t_critical, df, ncp)
power
```

## Facteurs importants

![Puissances statistiques sous différentes tailles d'effet et tailles d'échantillon](Slide-images\41592_2013_Article_BFnmeth2738_Fig4_HTML.jpg)

- **Référence** : Krzywinski, M., Altman, N. Power and sample size. *Nat Methods* **10**, 1139–1140 (2013). https://doi.org/10.1038/nmeth.2738

## Puissance statistique

Si nous n'avons pas encore collecté de données ...

Et nous voulons connaître la taille de l'échantillon pour atteindre une puissance statistique prédéfinie ...

# Détermination de la taille d'échantillon

Fixer les paramètres suivants :

- Taille de l'effet (d de Cohen) : il s'agit de la différence anticipée entre les moyennes de deux groupes divisée par l'écart type.

- Niveau de signification \(\alpha\) = 0,05.

- Puissance souhaitée \(1-\beta\) = 0,80.

```{r}
effect_size <- 0.5  # par ex. (mu1 - mu2) / sigma
alpha <- 0.05
power <- 0.80 
```
\pause

Trouver la **valeur t critique** pour le niveau de signification, puis utiliser la **distribution t non centrale** pour calculer la puissance.

## R code

```{r}
calculate_sample_size <- function(d, power, alpha) {
  n <- 2   # petit n sera incrémenté
  while(TRUE) {
    t_crit <- qt(1 - alpha/2, df = 2*n - 2)
    ncp <- sqrt(n) * d
    beta <- pt(t_crit, df = 2*n - 2, ncp = ncp) - 
            pt(-t_crit, df = 2*n - 2, ncp = ncp)
    current_power <- 1 - beta
    if (current_power >= power) {
      return(n)
    }
    n <- n + 1
  }
}
```
## R code (suite)

L'expression `pt(t_crit, df = 2*n - 2, ncp = ncp)` calcule la probabilité (sous la distribution t non-centrale) d'observer une valeur t inférieure ou égale à `t_crit`.

De même, `pt(-t_crit, df = 2*n - 2, ncp = ncp)` calcule la probabilité d'observer une valeur t inférieure ou égale à `-t_crit`.

La différence entre ces deux probabilités (`pt(t_crit, df = 2*n - 2, ncp = ncp) - pt(-t_crit, df = 2*n - 2, ncp = ncp)`) donne essentiellement la probabilité d'une erreur de Type II (\(\beta\)), qui est la probabilité de ne pas rejeter l'hypothèse nulle lorsque l'hypothèse alternative est vraie.
\pause

```{r}
calculate_sample_size(effect_size, power, alpha)
```

## Plus d'exemples

Utiliser le célèbre jeu de données iris, en nous concentrant sur les largeurs de sépales des espèces versicolor et virginica.

```{r}
versicolor <- 
  subset(iris, Species=="versicolor")$Sepal.Width
virginica <- 
  subset(iris, Species=="virginica")$Sepal.Width
```

![Iris dans une peinture de Vincent van Gogh](Slide-images\Irises-Vincent_van_Gogh.jpg){width=40%, height=40%}

## Préparation des données préliminaires

Prendre aléatoirement 5 points de données pour chacune des deux espèces (`versicolor` et `virginica`) dans la variable `Sepal.Width`.

```{r, echo=FALSE}
set.seed(123) # For reproducibility
```
```{r}
sample_versicolor <- sample(versicolor, 5)
sample_versicolor
```
```{r}
sample_virginica <- sample(virginica, 5)
sample_virginica
```

## Calcul de la puissance statistique

```{r}
# Calculate means and standard deviations
mean_versicolor <- mean(sample_versicolor)
mean_virginica <- mean(sample_virginica)
sd_versicolor <- sd(sample_versicolor)
sd_virginica <- sd(sample_virginica)

# Calculate pooled standard deviation
n <- 5 # sample size for each group
pooled_sd <- 
  sqrt(((n-1)*sd_versicolor^2 + 
          (n-1)*sd_virginica^2) / (n+n-2))

# Calculate effect size (Cohen's d)
effect_size <- (mean_versicolor-mean_virginica)/pooled_sd
effect_size
```

## Calcul de la puissance statistique (suite)

```{r}
# Calculate power using the effect size
alpha <- 0.05
t_critical <- qt(1 - alpha/2, df = 2*n - 2)
ncp <- effect_size * sqrt(n/2)
power <- 1 - 
  pt(t_critical, df = 2*n - 2, ncp = ncp) +
  pt(-t_critical, df = 2*n - 2, ncp = ncp)
power
```
\pause

Quelle serait la taille minimale de l'échantillon afin d'avoir une puissance d'au moins 0,80 ?
\pause

```{r}
desired_power <- 0.80
calculate_sample_size(effect_size, desired_power, alpha)
```

## Détermination de la taille d'échantillon

"The larger sample size, the more confidence you can be that your sample mean is a good representation of your population mean.

In other words, the N justifies the means."

# D'autre option du logiciel : G*Power

![G*Power](Slide-images\csm_GPowerIcon.png){width=25%, height=25%}

**Lien pour le télécharger** : [https://www.psychologie.hhu.de/arbeitsgruppen/allgemeine-psychologie-und-arbeitspsychologie/gpower](https://www.psychologie.hhu.de/arbeitsgruppen/allgemeine-psychologie-und-arbeitspsychologie/gpower)

En tous cas, en utilisant G*Power, \textcolor{brown}{il faut comprendre et précalculer le paramètre de noncentralité `ncp` (ou la notion de taille d'effet).}

# Travaux pratiques

À partir de la base de données "Pima Indian Diabetes", supposant que \(\alpha=0.05\) pour chacun des huit paramètres (`Pregnancies`, `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI`, `DiabetesPedigreeFunction` et `Age`) ...

1. Calculer la puissance statistique (\(1-\beta\)) pour détecter la différence entre les deux groupes de `Outcome`

2. Calculer la taille minimale de l'échantillon afin d'avoir une puissance statistique d'au moins 0,80

Essayez d'utiliser à la fois R et G*Power.
