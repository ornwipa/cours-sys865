---
title: "SYS865 Inférence statistique avec programmation R"
author: "Ornwipa Thamsuwan"
date: "31 janvier 2024"
# date: "`r format(Sys.time(), '%d-%m-%Y')`"
output:
  beamer_presentation: 
    slide_level: 2
    theme: "Goettingen"
    colortheme: "crane"
    fonttheme: "structurebold"
header-includes:
- \setbeamertemplate{navigation symbols}{}
- \setbeamertemplate{footline}[page number]
---

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

# Plan de la séance

- Récap
  - Échantillonage
  - Théorème Central Limite
  - Intervalle de confiance
- Tests d'hypothèse
  - Types d'erreur
  - Test sur la moyenne d'un échantillon
  - Test sur la moyenne des deux échantillons
  - Test nonparamétrique

# Récap et matière à réflexion

**Réponses anonymes**

Go to [wooclap.com](wooclap.com)

Enter the event code FFBQSE

![Lien à l'activité sur Wooclap](Wooclap-31-janvier-2023.png){width=50%, height=50%}

## Échantillonage

**Characteristiques de l'échantillonage probabilistique**

1. **Sélection aléatoire** : Les individus sont choisis de manière aléatoire, ce qui assure l'impartialité dans la sélection.

\pause

2. **Probabilité égale ou connue** : Chaque membre de la population a une chance égale ou connue d'être inclus dans l'échantillon. Ça permet d'avoir une représentation équitable de la population.

\pause

3. **Représentativité** : L'échantillon a de fortes chances d'être représentatif de la population globale. Cela rend possible de généraliser les résultats de l'échantillon à l'ensemble de la population.

## Échantillonage (suite)

**Characteristiques de l'échantillonage probabilistique**

4. **Inférence statistique** : Ces méthodes permettent de calculer des erreurs d'échantillonnage, des intervalles de confiance et de réaliser des tests de significativité. Cela offre la possibilité de tirer des conclusions statistiques sur la population à partir de l'échantillon.

![Inférence statistique](Slide-images\Population-Sample.png){width=25%, height=25%}

## Théorème Central Limite

À mesure que l'échantillon s'agrandit, la distribution de la moyenne de cet échantillon \( \overline{X}_n \) se rapproche d'une distribution normale, indépendamment de la forme de la distribution de la population.

![Théorème Central Limite](Slide-images\clt.jpg){width=70%, height=50%}

## Théorème Central Limite (suite)

Le Théorème Central Limite peut être résumé par l'équation suivante :

\[ \overline{X}_n \approx N\left(\mu, \frac{\sigma^2}{n}\right) \]

Où :

- \( \overline{X}_n \) est la moyenne de l'échantillon d'un ensemble de \( n \) variables aléatoires **\textcolor{brown}{indépendantes et identiquement distribuées}**.

- \( N\left(\mu, \frac{\sigma^2}{n}\right) \) indique que \( \overline{X}_n \) suit approximativement une distribution normale avec une moyenne \( \mu \) (la moyenne de la population) et une variance \( \frac{\sigma^2}{n} \) (la variance de la population divisée par la taille de l'échantillon \( n \)).

## Intervalle de confiance

Un IC est une plage de valeurs statistiques utilisée pour estimer la fiabilité d'une estimation d'un paramètre de population, comme la moyenne. Il est exprimé avec un niveau de confiance, indiquant la probabilité que cet intervalle contienne le vrai paramètre de la population.

### Lorsque \( \sigma \) est Connue

- Formule : \( CI = \overline{x} \pm z \times \frac{\sigma}{\sqrt{n}} \)

- \( z \) : Score Z de la distribution normale, correspondant au niveau de confiance souhaité.

### Lorsque \( \sigma \) est Inconnue

- Formule : \( CI = \overline{x} \pm t \times \frac{s}{\sqrt{n}} \)

- \( t \) : Score t de la distribution t, variant selon la taille de l'échantillon.

## Intervalle de confiance (dernier TP)

```{r, echo=FALSE}
data <- read.csv("diabetes.csv")

# Filter out 0 values from the Glucose column
filtered_data <- subset(data, Glucose > 0)

# Calculate density for each group
density_all <- density(filtered_data$Glucose, na.rm = TRUE)
density_outcome_0 <- density(subset(filtered_data, Outcome == 0)$Glucose, na.rm = TRUE)
density_outcome_1 <- density(subset(filtered_data, Outcome == 1)$Glucose, na.rm = TRUE)

# Find the range for the plot
x_lim_range <- range(density_all$x, density_outcome_0$x, density_outcome_1$x)
y_lim_range <- range(density_all$y, density_outcome_0$y, density_outcome_1$y)

# Set up the plot with appropriate limits
plot(density_all, xlim = x_lim_range, ylim = y_lim_range, 
     main = "Density Plot of Glucose", 
     xlab = "Concentration de Glucose Plasmatique à 2h (GTIT) [mg/dL]", 
     ylab = "Density", col = "black")

# Overlay the density plots for each group
lines(density_outcome_0, col = "blue")
lines(density_outcome_1, col = "red")

# Add a legend
legend("topright", legend = c("All", "Outcome 0 (non-diabetic)", "Outcome 1 (diabetic)"), 
       col = c("black", "blue", "red"), lty = 1, cex = 0.8)
```

\pause
\textcolor{red}{Les personnes diabétiques et non diabétiques ont-elles des niveaux différents du glucose plasmatique ?}

## Intervalle de confiance (dernier TP)

En appliquant le Théorème Central Limite ...

```{r, echo=FALSE}
# Calculate mean and standard deviation for each Outcome group
mean_glucose_0 <- mean(subset(filtered_data, Outcome == 0)$Glucose, na.rm = TRUE)
sd_glucose_0 <- sd(subset(filtered_data, Outcome == 0)$Glucose, na.rm = TRUE)

mean_glucose_1 <- mean(subset(filtered_data, Outcome == 1)$Glucose, na.rm = TRUE)
sd_glucose_1 <- sd(subset(filtered_data, Outcome == 1)$Glucose, na.rm = TRUE)

# Define a sequence of glucose values for plotting
glucose_range <- seq(min(filtered_data$Glucose, na.rm = TRUE), max(filtered_data$Glucose, na.rm = TRUE), length.out = 200)

# Calculate normal distribution values for each group
normal_values_0 <- dnorm(glucose_range, mean = mean_glucose_0, sd = sd_glucose_0)
normal_values_1 <- dnorm(glucose_range, mean = mean_glucose_1, sd = sd_glucose_1)

# Plot the normal probability distributions
plot(glucose_range, normal_values_0, type = 'l', col = 'blue', lwd = 2, 
     main = 'Normal Probability Distributions of Glucose by Outcome with 95% Confidence Intervals of the Means', 
     xlab = 'Concentration de Glucose Plasmatique à 2h (GTIT) [mg/dL]', 
     ylab = 'Density')
lines(glucose_range, normal_values_1, col = 'red', lwd = 2)

# Define a function to calculate the confidence interval
calculate_ci <- function(data, conf_level = 0.95) {
  mean_glucose <- mean(data$Glucose, na.rm = TRUE)
  sd_glucose <- sd(data$Glucose, na.rm = TRUE)
  n <- sum(!is.na(data$Glucose))
  
  alpha <- 1 - conf_level
  se <- sd_glucose / sqrt(n)
  t_critical <- qt(1 - alpha/2, df = n - 1)
  margin_error <- t_critical * se
  
  ci_lower <- mean_glucose - margin_error
  ci_upper <- mean_glucose + margin_error
  
  return(c(lower = ci_lower, upper = ci_upper))
}

# Calculate CI for filtered data and each Outcome group
ci_outcome_0 <- calculate_ci(subset(filtered_data, Outcome == 0))
ci_outcome_1 <- calculate_ci(subset(filtered_data, Outcome == 1))

# Add CI lines for each group
abline(v = ci_outcome_0["lower"], col = "blue", lty = 2)
abline(v = ci_outcome_0["upper"], col = "blue", lty = 2)
abline(v = ci_outcome_1["lower"], col = "red", lty = 2)
abline(v = ci_outcome_1["upper"], col = "red", lty = 2)

# Add a legend
legend("topright", legend = c("Outcome 0", "Outcome 1"), col = c("blue", "red"), lwd = 2)
```

\pause
\textcolor{red}{Les deux moyennes sont-elles différentes ?}

## Plan de la séance

- Récap
  - Échantillonage
  - Théorème Central Limite
  - Intervalle de confiance
- Test d'hypothèse
  - Types d'erreur
  - Test sur la moyenne d'un échantillon
  - Test sur la moyenne des deux échantillons
  - Test nonparamétrique

# Types d'erreur

**Erreur de type I (faux positif)** : l'enquêteur rejette une *hypothèse nulle* qui est réellement vraie dans la population.

**Erreur de type II (faux négatif)** : l’investigateur ne parvient pas à rejeter une *hypothèse nulle* qui est en réalité fausse dans la population.

\pause
... mais quelle est l'hypothèse nulle ?

\pause
Alors, voici un exemple ...

![Erreur de type I et II](Slide-images\Type-1-and-2-Error-reddit.png){width=60%, height=30%}

## Erreur type I

**Alpha \( \alpha \)** représente le seuil de probabilité de commettre une erreur de type I dans un test d'hypothèse. C'est la probabilité maximale acceptable de rejeter à tort l'hypothèse nulle. 

Communément fixé à 0,05 (5 %), un \( \alpha \) de 0,05 signifie qu'il y a 5 % de chances de rejeter l'hypothèse nulle alors qu'elle est en réalité vraie.

Réduire \( \alpha \) diminue les chances d'une erreur de type I, mais augmente le risque d'une erreur de type II.

## Erreur type II

**Beta \( \beta \)** représente la probabilité de commettre une erreur de type II dans un test d'hypothèse. C'est la probabilité de ne pas rejeter une hypothèse nulle fausse. 

La puissance d'un test, qui est \( 1 - \beta \), indique la capacité du test à rejeter correctement une fausse hypothèse nulle. 

Réduire \( \beta \) (augmentant ainsi la puissance) nécessite souvent d'augmenter la taille de l'échantillon ou la taille de l'effet.

## Types d'erreur : mise en application

En supposant que le paramètre "Glucose" est normalement distribué ...

```{r, echo=FALSE}
# Calculate mean and standard deviation for each Outcome group
mean_glucose_0 <- mean(subset(filtered_data, Outcome == 0)$Glucose, na.rm = TRUE)
sd_glucose_0 <- sd(subset(filtered_data, Outcome == 0)$Glucose, na.rm = TRUE)

mean_glucose_1 <- mean(subset(filtered_data, Outcome == 1)$Glucose, na.rm = TRUE)
sd_glucose_1 <- sd(subset(filtered_data, Outcome == 1)$Glucose, na.rm = TRUE)

# Define a sequence of glucose values for plotting
glucose_range <- seq(min(filtered_data$Glucose, na.rm = TRUE), max(filtered_data$Glucose, na.rm = TRUE), length.out = 200)

# Calculate normal distribution values for each group
normal_values_0 <- dnorm(glucose_range, mean = mean_glucose_0, sd = sd_glucose_0)
normal_values_1 <- dnorm(glucose_range, mean = mean_glucose_1, sd = sd_glucose_1)

# Plot the normal probability distributions
plot(glucose_range, normal_values_0, type = 'l', col = 'blue', lwd = 2, 
     main = 'Normal Probability Distributions of Glucose by Outcome', 
     xlab = 'Concentration de Glucose Plasmatique à 2h (GTIT) [mg/dL]', 
     ylab = 'Density')
lines(glucose_range, normal_values_1, col = 'red', lwd = 2)

# Add a legend
legend("topright", legend = c("Outcome 0", "Outcome 1"), col = c("blue", "red"), lwd = 2)
```

## Erreur type I

Une concentration de glucose plasmatique (à 2h) est supérieure à 140 mg/dL quand la personne n'est pas diabétique.

```{r, echo=FALSE}
# Plot the normal probability distributions
plot(glucose_range, normal_values_0, type = 'l', col = 'blue', lwd = 2, 
     main = 'Normal Probability Distributions of Glucose by Outcome', 
     xlab = 'Concentration de Glucose Plasmatique à 2h (GTIT) [mg/dL]', 
     ylab = 'Density', ylim = c(0, max(normal_values_0, normal_values_1)))
lines(glucose_range, normal_values_1, col = 'red', lwd = 2)

# Add a vertical line at x=140
abline(v = 140, col = "black", lwd = 2, lty = 2)

# Highlight the area under the blue curve to the right of x=140 (Type I error area for Outcome 0)
x_area <- glucose_range[glucose_range > 140]
y_area <- dnorm(x_area, mean = mean_glucose_0, sd = sd_glucose_0)
polygon(c(140, x_area, max(glucose_range)), c(0, y_area, 0), col = "lightblue", border = NA)

# Add a legend
legend("topright", legend = c("Outcome 0", "Outcome 1", "Erreur type I (Valeur supérieur à 140)"), 
       col = c("blue", "red", "lightblue"), lty = 1, lwd = 2, bty = "n")
```

## Erreur type II

Une concentration de glucose plasmatique (à 2h) est inférieure à 140 mg/dL quand la personne est diabétique.

```{r, echo=FALSE}
# Plot the normal probability distributions
plot(glucose_range, normal_values_0, type = 'l', col = 'blue', lwd = 2, 
     main = 'Normal Probability Distributions of Glucose by Outcome', 
     xlab = 'Concentration de Glucose Plasmatique à 2h (GTIT) [mg/dL]', 
     ylab = 'Density', ylim = c(0, max(normal_values_0, normal_values_1)))
lines(glucose_range, normal_values_1, col = 'red', lwd = 2)

# Add a vertical line at x=140
abline(v = 140, col = "black", lwd = 2, lty = 2)

# Highlight the area under the red curve to the left of x=140 (Type II error area for Outcome 1)
x_area <- glucose_range[glucose_range < 140]
y_area <- dnorm(x_area, mean = mean_glucose_1, sd = sd_glucose_1)
polygon(c(min(glucose_range), x_area, 140), c(0, y_area, 0), col = "lightcoral", border = NA)

# Add a legend
legend("topright", legend = c("Outcome 0", "Outcome 1", "Erreur Type II (Valeur inferieur à 140)"), 
       col = c("blue", "red", "lightcoral"), lty = 1, lwd = 2, bty = "n")
```

## Tableau de contingence

Ou en utilisant directement les décomptes de données ...

\pause
Discrétiser la variable 'Glucose'
```{r}
data$GlucoseCtgr <- ifelse(data$Glucose < 140, 
                               "Less than 140", 
                               "140 and above")
```

\pause
Créer un tableau de contingence avec les variables discrètes 'GlucoseCtgr' et 'Outcome'
```{r}
contingency <- table(data$GlucoseCtgr, data$Outcome)
print(contingency)
```

## Tableau de contingence (suite)

Quels sont les valeurs de \( \alpha \) et \( \beta \) ?

\pause
- Erreur type I : 'Glucose' est '140 and above' et 'Outcome' est 0.

- Erreur type II : 'Glucose' est 'Less than 140' et 'Outcome' est 1.

\pause

La mauvaise manière ... \textcolor{red}{à éviter!}
```{r}
contingency_prb <- prop.table(contingency)
print(contingency_prb)
```

## Tableau de contingence (suite)

La bonne manière ...
```{r}
total_negatives <- sum(contingency[, "0"])
false_positives <- contingency["140 and above", "0"]
alpha <- false_positives / total_negatives
cat("Alpha (Type I error rate):", alpha, "\n")

total_positives <- sum(contingency[, "1"])
false_negatives <- contingency["Less than 140", "1"] 
beta <- false_negatives / total_positives
cat("Beta (Type II error rate):", beta, "\n")
```

## Types d'erreur : conclusion

- **\( \alpha \)** : Probabilité d'un faux positif (erreur de type I).
- **\( \beta \)** : Probabilité d'un faux négatif (erreur de type II).
- Équilibrer \( \alpha \) et \( \beta \) est crucial dans les tests d'hypothèses, car la diminution de l'un augmente souvent l'autre. Le choix de \( \alpha \) et \( \beta \) est influencé par le contexte de l'étude et l'importance relative des erreurs dans le scénario de recherche spécifique.

![Équilibre entre \(\alpha\) et \(\beta\)](Slide-images\erreurdetype.jpg){width=35%, height=35%}

# Tests d'hypothèse

Les tests d'hypothèses sont utilisés pour déterminer s'il existe suffisamment de preuves pour soutenir une croyance ou une théorie particulière sur un paramètre de population.
\pause

Exemples dans le génie mécanique :

- Tester si un matériau composite possède une résistance à la traction supérieure à celle d'un matériau standard.

- Comparer l'efficacité thermique de deux liquides de refroidissement moteur différents.

- Analyser si une nouvelle technique d'amortissement des vibrations réduit plus efficacement les vibrations qu'une méthode actuelle. 

## Hypothèse nulle (\( H_0 \)) et alternative (\( H_1 \))

L'**hypothèse nulle** est une déclaration indiquant qu'il n'y a aucun effet ou aucune différence dans un contexte particulier. C'est une position par défaut suggérant que toute différence ou signification observée dans un ensemble de données est purement due au hasard.
\pause

L'**hypothèse alternative** est ce que l'on souhaite prouver. C'est une déclaration qui indique une différence ou un effet. Cette hypothèse est acceptée uniquement lorsque les données fournissent suffisamment de preuves pour rejeter l'hypothèse nulle.

## Démarches dans les tests d'hypothèses

Dans les tests d'hypothèses, on commence par supposer que l'hypothèse nulle est vraie. Ensuite, en fonction des données de l'échantillon, on teste cette hypothèse. Si les preuves sont suffisamment fortes contre \(H_0\), on la rejette en faveur de \(H_1\). La décision est souvent prise en utilisant les valeurs \(p\) et des niveaux de signification prédéfinis (comme \(\alpha = 0,05\)).

# Test sur la moyenne d'un échantillon

### 1. Formulation des hypothèses

\(H_0\) postule que la moyenne de la population (\(\mu\)) est égale à une valeur spécifique (\(\mu_0\)). 

- Formellement, \(H_0:\mu=\mu_0\)

\(H_1\) ou \(H_a\) suggère que la moyenne de la population diffère de cette valeur. 

- \(H_0:\mu\neq\mu_0\) (test bilatéral), \(H_0:\mu>\mu_0\) (test unilatéral droit), ou \(H_0:\mu<\mu_0\) (test unilatéral gauche)

\pause
### 2. Collecte de données et calculs statistiques

À partir des données collectées, calculer

- la moyenne de l'échantillon (\( \overline{x} \)),

- l'écart-type de l'échantillon (\( s \)) et

- la taille de l'échantillon (\( n \)).

## Test sur la moyenne d'un échantillon

### 3. Choix du test statistique et calculs

Utiliser un test (\( t \)) de Student pour comparer la moyenne de l'échantillon à la valeur spécifiée (\(\mu_0\)). 

- \( t = \frac{\overline{x} - \mu_0}{s / \sqrt{n}} \).

\pause
### 4. Décision statistique et interprétation

Déterminer une **valeur critique** par le niveau de signification \(\alpha\) (souvent 0,05). 

\pause
Si la valeur \( t \) est *en dehors des limites* de la valeur critique, rejeter \(H_0\).

Rejeter \(H_0\) indique que la moyenne de la population diffère significativement de \(\mu_0\). 

\pause
Si \(H_0\) n'est pas rejetée, il n'y a pas suffisamment de preuves pour affirmer que la moyenne de la population est différente de \(\mu_0\).

## Valeur critique

La **valeur critique** est un seuil utilisé pour déterminer si la statistique de test calculée (comme une valeur \( t \) ou \( z \)) indique un résultat statistiquement significatif, à partir de laquelle on décide de rejeter ou non l'hypothèse nulle.

\pause
La valeur critique est déterminée en fonction du niveau de signification \( \alpha \) (souvent 0,05) et, pour un test \( t \), du nombre de degrés de liberté (\( df \) ou "degree of freedom" en anglais).

\pause
```{r}
qt(1 - 0.05/2, df = 29)
```

\pause
Pour un test \( z \), la valeur critique dépend de la distribution normale standard, \( N(0,1) \).

\pause
```{r}
qnorm(0.975)
```

## Tests d'hypothèse avec la distribution t

### Test bilatéral (à deux queues)

- **Valeur critique** : \( t_{\alpha/2, \text{df}} \) et \( -t_{\alpha/2, \text{df}} \)
- Rejeter de \(H_0\) si \( t_{\text{test}} > t_{\alpha/2, \text{df}} \) ou \( t_{\text{test}} < -t_{\alpha/2, \text{df}} \)

### Test unilatéral gauche (à queue gauche)

- **Valeur critique** : \( t_{\alpha, \text{df}} \)
- Rejeter de \(H_0\) si \( t_{\text{test}} < -t_{\alpha, \text{df}} \)

### Test unilatéral droit (à queue droite)

- **Valeur critique** : \( t_{\alpha, \text{df}} \)
- Rejeter de \(H_0\) si \( t_{\text{test}} > t_{\alpha, \text{df}} \)

## Tests d'hypothèse avec la distribution t

![Rejeter \(H_0\)](Slide-images\rejecth0.png){width=70%, height=70%}

## Exemples avec R

À partir de la base des données "Pima Indian Diabetes" ...

Nous voulons tester si la population étudiée a un IMC moyen considéré comme normal, défini entre 18,5 et 24,9, avec un niveau de signification \(\alpha\) de 0,05.

\pause
**1. Formulation des hypothèses**

**\(H_0\)** : La moyenne de l'IMC de la population est normale (c'est-à-dire, située dans la plage 18.5 - 24.9).

- **Formellement**: \(H_0: 18.5 \leq \mu \leq 24.9\)

**\(H_1\)** : La moyenne de l'IMC de la population n'est pas normale (c'est-à-dire, en dehors de la plage 18.5 - 24.9).

- **Formellement**: \(H_1: \mu < 18.5\) ou \(\mu > 24.9\)

## Exemples avec R (suite)

**2. Collecte de données et calculs statistiques**

```{r}
filtered_bmi <- data$BMI[data$BMI>0 & !is.na(data$BMI)]
mean_bmi <- mean(filtered_bmi)
sd_bmi <- sd(filtered_bmi)
n <- length(filtered_bmi)
```

\pause
**3. Choix du test statistique et calculs**
```{r}
mu_0_lower <- 18.5
mu_0_upper <- 24.9
tstat_upper <- (mean_bmi-mu_0_lower) / (sd_bmi/sqrt(n))
tstat_lower <- (mean_bmi-mu_0_upper) / (sd_bmi/sqrt(n))
cat(tstat_lower, tstat_upper)
```

## Exemples avec R (suite)

**4. Décision statistique et interprétation**

Déterminer les valeurs critiques \( t_{-\alpha/2} \) et \( t_{\alpha/2} \)

\pause
```{r}
alpha <- 0.05
tcrit_lower <- qt(alpha/2, df = n-1)
tcrit_upper <- qt(1 - alpha/2, df = n-1)
cat(tcrit_lower, tcrit_upper)
```

\pause
Les statistiques \(t\) sont supérieures aux valeurs critiques. Donc, rejeter \(H_0\) et conclure que l'IMC moyen n'est pas normal.

# Test sur la moyenne des deux échantillons

## Quelques exercices stimulants ...

**Réponses anonymes**

Go to [wooclap.com](wooclap.com)

Enter the event code FFBQSE

![Lien à l'activité sur Wooclap](Wooclap-31-janvier-2023.png){width=50%, height=50%}

## Test t pour deux échantillons indépendants

### 1. Hypothèses

**\(H_0\)** : La moyenne de la première population (\( \mu_1 \)) est égale à la moyenne de la seconde population (\( \mu_2 \)). 

- Formellement, \(H_0\): \( \mu_1 = \mu_2 \)

**\(H_1\)** : Les moyennes des deux populations sont différentes.

- Formellement, \(H_1\): \( \mu_1 \neq \mu_2 \)

\pause
### 2. Conditions du test \textcolor{red}{-- Important!}

- Les échantillons sont indépendants.
- Les échantillons sont suffisamment grands ou proviennent de distributions normalement distribuées.
- Les variances des deux populations sont supposées égales.

## Test t pour deux échantillons indépendants

### 3. Statistique de test

La statistique de test \(t\) est calculée comme suit :
\[ t = \frac{\overline{x}_1 - \overline{x}_2}{\sqrt{s_p^2 \left(\frac{1}{n_1} + \frac{1}{n_2}\right)}} \]
où \( \overline{x}_1 \) et \( \overline{x}_2 \) sont les moyennes des échantillons, \( n_1 \) et \( n_2 \) les tailles des échantillons, et \( s_p^2 \) la variance combinée.

## Test t pour deux échantillons indépendants

### 4. Décision et interprétation

Comparer la valeur de \(t\) calculée à une valeur critique de la distribution \(t\).

- Les degrés de liberté sont df = \( n_1 + n_2 - 2 \).

- Le niveau de signification habituel : \( \alpha = 0.05 \).

- Rejeter H0 si \( |t| > t_{\text{critique}} \).

\pause
Rejeter \(H_0\) indique une différence statistiquement significative entre les moyennes des deux populations. 

Si \(H_0\) n'est pas rejetée, cela suggère l'absence de preuve suffisante d'une différence.

## Test t pour deux échantillons appariés

Pour des échantillons appariés, la méthode est similaire mais basée sur les différences appariées entre les deux ensembles de données.

\pause
Quelques exemples :

- Mesurer la capacité de charge d'une batterie *avant* et *après* un nombre de cycles de charge pour déterminer la perte de capacité au fil du temps

- Comparer la force d'un joint soudé *avant* et *après* un processus de vieillissement accéléré pour simuler l'effet à long terme de l'utilisation

- Évaluer la préférence ou le confort d'utilisateurs avec deux designs différents d'un produit pour déterminer lequel est ergonomiquement supérieur (A|B testing)

## Test t pour deux échantillons appariés

### Hypothèse
\[ H_0: \mu_{\text{diff}} = 0 \]
\[ H_1: \mu_{\text{diff}} \neq 0 \]

où \( \mu_{\text{diff}} \) est la moyenne des différences entre les paires.

\pause

### Statistique de test
\[ t = \frac{\overline{d}}{s_d / \sqrt{n}} \]
où \( \overline{d} \) est la moyenne des différences entre les deux mesures \( d_i = x_{i1} - x_{i2} \) pour chaque paire \( i \), \( s_d \) est l'écart-type des différences et \( n \) est le nombre de paires.

## Exemples avec R

À partir de la base des données "Pima Indian Diabetes" ...

Nous voulons tester si les IMC des deux groupes (diabétiques et non diabétiques) sont égaux.

\pause
\textcolor{red}{Les deux groupes sont-ils indépendants ou appariés ?}

\pause
Séparer des données en deux groupes basés sur 'Outcome'
```{r}
filtered_data <- subset(data, BMI > 0)
bmi_non_diabetic <- 
  filtered_data$BMI[filtered_data$Outcome == 0]
bmi_diabetic <- 
  filtered_data$BMI[filtered_data$Outcome == 1]
```

## Exemples avec R (suite)

Vérifier la condition d'homogénéité des variances
```{r}
var.test(bmi_non_diabetic, bmi_diabetic)
```

## Exemples avec R (suite)

Effectuer le test t pour échantillons indépendants
```{r}
t.test(bmi_non_diabetic, bmi_diabetic,
       var.equal = TRUE)
```

## Attention!

Les données ne sont pas normalement distribuées. Alors, il faut utiliser un test non paramétrique.
```{r}
shapiro.test(bmi_non_diabetic)
shapiro.test(bmi_diabetic)
```

# Test non paramétrique

## Test de Wilcoxon

Le test de Wilcoxon est un test \textcolor{brown}{non paramétrique} utilisé pour comparer les moyennes des deux échantillons. Il est utilisé lorsque les conditions pour un test paramétrique (test \(t\)) ne sont pas remplies.
\pause

- **Test de Rang Somme de Wilcoxon** : Utilisé pour comparer deux échantillons indépendants. Ce test est également connu sous le nom de test de Mann-Whitney.

- **Test de Wilcoxon pour Échantillons Appariés** : Utilisé pour comparer deux échantillons appariés ou mesures répétées sur un même groupe (par exemple, avant et après un traitement).

## Exemples avec R

Avec les mêmes données ...
```{r}
wilcox.test(bmi_non_diabetic, bmi_diabetic)
```

# Résumé des démarches

**Réponses anonymes**

Go to [wooclap.com](wooclap.com)

Enter the event code FFBQSE

![Lien à l'activité sur Wooclap](Wooclap-31-janvier-2023.png){width=50%, height=50%}

## Réponse correcte

![Démarches de test d'hypothèse](Slide-images\sortingcorrect.JPG){width=80%, height=80%}

# Travaux pratiques

Pour chacun des huit variables (`Pregnancies`, `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI`, `DiabetesPedigreeFunction` et `Age`) dans la base de données sur les diabètes ...

1. Vérifier les conditions pour utiliser un test paramétrique

2. Effectuer le test \(t\) ou Wilcoxon pour comparer les moyennes entre les deux groupes : non diabétique (`Outcome`=0) et diabétique (`Outcome`=1)

3. Interpréter les résultats