---
title: "SYS865 Inférence statistique avec programmation R"
author: "Ornwipa Thamsuwan"
date: "20 mars 2024"
output:
  beamer_presentation:
    slide_level: 2
    theme: Goettingen
    colortheme: crane
    fonttheme: structurebold
  ioslides_presentation: default
header-includes:
- \setbeamertemplate{navigation symbols}{}
- \setbeamertemplate{footline}[page number]
---

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

# Plan de la séance

- Régression logistique
- Confondeur

# Récap et matière à réfléxion

Base de données "Pima Indian Diabetes"

- Variable dépendante : `Outcome`
- Variables indépendantes : `Pregnancies`, `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI`, `DiabetesPedigreeFunction` et `Age`

\pause
**R code**
```{r}
data <- read.csv("diabetes.csv")
selected_columns <- data[, 2:6]
rows_with_zero <- apply(selected_columns, 1, 
                        function(x) any(x == 0))
data_cleaned <- data[!rows_with_zero, ]
names(data_cleaned)[
  names(data_cleaned) == 
    "DiabetesPedigreeFunction"] <- "DbtPdgFunc"
```

## Recap : Modèle complet

```{r}
model_full <- lm(Outcome ~ Pregnancies + Glucose + 
                   BloodPressure + SkinThickness + 
                   Insulin + BMI + DbtPdgFunc + Age,
                 data = data_cleaned)
round(summary(model_full)$coefficients, 4)
```

## Recap : Modèle ajusté

En supprimant les variables non importantes `BloodPressure`, `SkinThickness` et `Insulin` ...

```{r}
model_reduced <- lm(Outcome ~ Pregnancies + Glucose + 
                      BMI + DbtPdgFunc + Age,
                    data = data_cleaned)
round(summary(model_reduced)$coefficients, 4)
```

## Recap : Comparaison des modèles par R² et R² ajusté

```{r}
summary(model_full)$r.squared
summary(model_reduced)$r.squared
```
\pause
```{r}
summary(model_full)$adj.r.squared
summary(model_reduced)$adj.r.squared
```

## Recap : Intervalles de confiance de \(\beta\)'s

```{r}
round(confint(model_reduced, level = 0.95), 4)
```

## Recap : Visualisation des résultats

```{r, echo=FALSE, warning=FALSE}
# Adjust plot margins to create space for the legend at the bottom
# Increase the bottom margin (first number)
par(mar=c(10, 4.1, 4.1, 2.1) + 0.1)  # Default is c(5.1, 4.1, 4.1, 2.1)

# Scatter plot
plot(data_cleaned$Glucose, data_cleaned$Outcome, 
     main="Scatter Plot of Glucose vs Outcome",
     xlab="Glucose", ylab="Outcome", pch=19, col=rgb(0,0,1,0.5))
abline(model_reduced, col="red")

linear_model <- lm(Outcome ~ Glucose, data=data_cleaned)
abline(linear_model, col="brown")

# Add a legend
legend(x="bottom", # Position of the legend
       legend=c("Linear model for Outcome ~ Pregnancies + Glucose + BMI + DbtPdgFunc + Age", 
                "Linear model for Outcome ~ Glucose"), # Labels
       col=c("red", "brown"), 
       lty=1, # Line types
       cex=1.2, # Increase text size
       xpd=TRUE, # Allow plotting outside the plot area
       inset=c(0, -0.4)) # Adjust horizontal and vertical position
```

\pause
La réponse (`y` ou `Outcome`) n'est pas une variable continues, mais binaire, soit 0 ou 1 et \textcolor{red}{non une valeur intermédiare.}

## Attention!

![Extrapolation - "Sustainable is unsustainable."](Slide-images\1.-sustainable.png){width=80%, height=80%}

## Recap : Visualisation des résultats

```{r, echo=FALSE, warning=FALSE}
par(mar=c(10, 4.1, 4.1, 2.1) + 0.1)  # Default is c(5.1, 4.1, 4.1, 2.1)

# Scatter plot
plot(data_cleaned$Glucose, data_cleaned$Outcome, 
     main="Scatter Plot of Glucose vs Outcome",
     xlab="Glucose", ylab="Outcome", pch=19, col=rgb(0,0,1,0.5))

linear_model <- lm(Outcome ~ Glucose, data=data_cleaned)
abline(linear_model, col="brown")

logistic_model <- glm(Outcome ~ Glucose, data=data_cleaned, family=binomial)
logistic_curve <- function(x) {
  predict(logistic_model, newdata=data.frame(Glucose=x), type="response")
}
curve(logistic_curve(x), add=TRUE, col="darkgreen")

# Add a legend
legend(x="bottom", # Position of the legend
       legend=c("Linear model for Outcome ~ Glucose",
                "Logistic model for Outcome ~ Glucose"), # Labels
       col=c("brown", "darkgreen"), 
       lty=1, # Line types
       cex=1.2, # Increase text size
       xpd=TRUE, # Allow plotting outside the plot area
       inset=c(0, -0.4)) # Adjust horizontal and vertical position
```

Une alternative est la régression logistique, fournissant un résultat sous forme de **probabilité** que `y` soit 0 ou 1.

## Introduction au nouveau sujet

![Régression linéaire vs. logistique](Slide-images\linear-regression-vs-logistic-regression.png){width=50%, height=50%}

# Régression logistique

## Régression logistique : Modèle

La régression logistique modélise la probabilité d'un résultat binaire basée sur une ou plusieurs variables prédictives. Cela est particulièrement utile lorsque la variable dépendante ne peut prendre que deux résultats possibles (succès ou échec).

\pause
Le modèle de régression logistique est basé sur **la fonction logit, le logarithme naturel du rapport de cotes**.

  \[ \ln\left(\frac{p}{1 - p}\right) = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_kX_k \]

- \( p \) est la probabilité d'une des issues (réponses),
- \( X_1, X_2, ..., X_k \) sont les variables prédictives.
- \( \beta_1, \beta_2, ..., \beta_k \) représentent le changement dans le log des cotes de l'issue pour un changement unitaire dans les variables prédictives.

## Régression logistique : Inférence

**Inférence sur les Coefficients** : Les tests d'hypothèse sur \( \beta_1, \beta_2, ..., \beta_k \) sont réalisées pour déterminer si les prédicteurs sont significativement associés à l'issue.

\pause
<br>

**Méthode d'Estimation** : Les coefficients sont estimés en utilisant l'Estimation du Maximum de Vraisemblance (MLE) afin de trouver les coefficients qui maximisent la vraisemblance d'observer les données de l'échantillon.

\pause
<br>

**Interprétation en Rapport de Cotes** : Un rapport de cotes supérieur à 1 indique une augmentation des cotes de l'issue avec une augmentation unitaire du prédicteur, et vice versa.

## Régression logistique : Choix des variables

**Guides généraux**

- Commencez avec un **cadre théorique** ou des recherches antérieures pour identifier les prédicteurs potentiels.
\pause

- Prenez en compte la **signification statistique** des variables dans les analyses préliminaires.
\pause

- Vérifiez la **multicollinéarité** parmi les prédicteurs, car une forte collinéarité peut déformer l'estimation et l'interprétation des coefficients.
\pause

- Évitez d'inclure trop de variables, surtout dans de petits ensembles de données, pour prévenir le **surajustement**.
\pause

### Méthodes de sélection séquentielles

- Ajouter ou retirer des prédicteurs basés sur des critères tels que l'AIC ou le BIC.

## Critère d'Information d'Akaike (AIC)

L'AIC est une mesure de la qualité **relative** d'un modèle statistique pour un ensemble de données, et basé sur le concept d'\textcolor{red}{entropie d'information}.

\pause
- \( AIC = 2k - 2\ln(L) \)
  - \( k \) est le nombre de paramètres dans le modèle et 
  - \( L \) est la vraisemblance du modèle.
  
L'AIC pénalise les modèles pour leur complexité (nombre de paramètres), aidant ainsi à éviter le surajustement.
  
\pause
- \textcolor{red}{Une valeur AIC plus basse indique un meilleur modèle.}
- Lors de la comparaison de modèles, la valeur absolue de l'AIC n'est pas aussi importante que la différence entre les valeurs AIC de différents modèles.
- Des modèles avec un AIC différant de plus de 2 sont généralement considérés comme ayant des preuves substantielles contre le modèle avec l'AIC le plus élevé.

## Critère d'Information Bayésien (BIC)

Le BIC, dérivé de la \textcolor{red}{probabilité bayésienne}, introduit une pénalité plus forte pour le nombre de paramètres dans le modèle.

\pause
- \( BIC = \ln(n)k - 2\ln(L) \)
  - \( n \) est le nombre d'observations,
  - \( k \) est le nombre de paramètres, et
  - \( L \) est la vraisemblance du modèle.

Le BIC a tendance à pénaliser plus lourdement la complexité que l'AIC, surtout à mesure que la taille de l'échantillon augmente.

\pause
- \textcolor{red}{Une valeur BIC plus basse indique un meilleur modèle.}
- La règle de décision pour comparer les modèles avec le BIC est similaire à l'AIC.
- Une différence de 6 ou plus est considérée comme une preuve forte contre le modèle avec le BIC le plus élevé.

## R code

```{r}
AIC(logistic_model)
BIC(logistic_model)
# calcul du BIC par 
# la fonction AIC avec l'argument k = log(n)
AIC(logistic_model, k = log(nrow(data_cleaned)))
```

## AIC vs. BIC

L'AIC se concentre davantage sur l'adéquation (goodness of fit) du modèle. Il est issu de la théorie de l'information et vise à choisir un modèle qui explique le mieux les données, même s'il comprend plus de paramètres.

Le BIC est dérivé de la probabilité bayésienne et est plus concerné par l'identification du vrai modèle parmi l'ensemble des candidats. Il part du principe qu'il existe un vrai modèle et tente de s'en rapprocher.

\pause

**Différences clés dans l'utilisation**

- Complexité : L'AIC peut sélectionner des modèles plus complexes, tandis que le BIC a tendance à favoriser des modèles plus simples.

- But : L'AIC est mieux adapté aux modèles axés sur la prédiction, tandis que le BIC est plus approprié pour les modèles visant à expliquer la structure sous-jacente.

# Démarches de sélection des variables de modèle

## Exemple : Sélection progressive

Examiner la corrélation de toutes les variables indépendantes avec la variable dépendante `Outcome`

```{r, echo=FALSE}
# Calculate the correlation matrix
cor_matrix <- cor(data_cleaned[, sapply(data_cleaned, is.numeric)], use = "complete.obs")

# Get the name of the last column (assuming this is your outcome variable)
last_column_name <- colnames(cor_matrix)[ncol(cor_matrix)]

# Print correlations with the last column for each variable
for (row_name in rownames(cor_matrix)) {
  correlation_with_last_column <- cor_matrix[row_name, last_column_name]
  print(paste(row_name, ":", round(correlation_with_last_column, 4)))
}
```

- Ajouter d'abord `Glucose`, puis `Age`, `Insulin`, `BMI`, ... etc. 

## Exemple : Sélection progressive

```{r}
model1 <- glm(Outcome ~ Glucose, 
              data=data_cleaned, family=binomial)
AIC(model1)
```

\pause

```{r}
model2 <- glm(Outcome ~ Glucose + Age, 
              data=data_cleaned, family=binomial)
AIC(model2)
```

- Garder `model2` et continuer à ajouter des variables

## Exemple : Sélection progressive

```{r}
model3 <- glm(Outcome ~ Glucose + Age + Insulin, 
              data=data_cleaned, family=binomial)
AIC(model3)
```

- Retourner au `model2` et ne pas inclure `Insulin`

\pause

- Essayer la prochaine variable `BMI`

```{r}
model4 <- glm(Outcome ~ Glucose + Age + BMI, 
              data=data_cleaned, family=binomial)
AIC(model4)
```

- Garder `model4` et continuer à ajouter des variables

## Exemple : Sélection progressive

*Le reste du processus sera consacré aux travaux pratiques.*

**Modèle à jour**

```{r, warning=FALSE}
round(summary(model4)$coefficients, 4)
```

## Exemple : Sélection régressive

Commencer par une modèle complet

```{r, echo=FALSE}
modelf <- glm(Outcome ~ Pregnancies + Glucose + BloodPressure +
                SkinThickness + Insulin + BMI + DbtPdgFunc + Age, 
              data=data_cleaned, family=binomial)
round(summary(modelf)$coefficients, 4)
```

- Éliminer `BloodPressure`, `SkinThickness`, `Insulin`, `Pregnancies`, ... une variable à la fois

## Exemple : Sélection régressive

```{r}
AIC(modelf) # modèle complète
```

\pause

```{r}
model5 <- glm(Outcome ~ Pregnancies + Glucose +
                SkinThickness + Insulin + BMI + 
                DbtPdgFunc + Age, 
              data=data_cleaned, family=binomial)
AIC(model5)
```

- Ne pas garder `model5` (ne pas retirer `BloodPressure`), mais essayer de retirer les autres variables

## Exemple : Sélection régressive

```{r}
model6 <- glm(Outcome ~ Pregnancies + Glucose +
                BloodPressure + Insulin + BMI + 
                DbtPdgFunc + Age,  
              data=data_cleaned, family=binomial)
AIC(model6)
```

\pause

```{r}
model7 <- glm(Outcome ~ Pregnancies + Glucose +
                BloodPressure + SkinThickness +
                BMI + DbtPdgFunc + Age,  
              data=data_cleaned, family=binomial)
AIC(model7)
```

- Ne retirer ni `SkinThickness` ni `Insulin`

## Exemple : Sélection régressive

Mais, si on essayait de retirer ces trois variables (`BloodPressure`, `SkinThickness` et `Insulin`) en même temps ...

```{r}
model8 <- glm(Outcome ~ Pregnancies + Glucose +
                BMI + DbtPdgFunc + Age,  
              data=data_cleaned, family=binomial)
AIC(model8)
```

- Selon l'AIC, le modèle s'améliore.

*Le reste du processus sera consacré aux travaux pratiques.*

## Présentation des modèles

Les **intervalles de confiance** des variables statistiquement significatives ne couvrent pas 0. 

```{r, echo=FALSE}
round(confint(modelf, level = 0.95), 4)
```

# Récap et matière à réfléxion

## Multicollinéarité

**Corrélations modérées entre variables indépendantes**

```{r}
cor(data_cleaned$Pregnancies, data_cleaned$Age)
cor(data_cleaned$Glucose, data_cleaned$Insulin)
cor(data_cleaned$SkinThickness, data_cleaned$BMI)
```

## Comparaison des modèles

```{r}
model2 <- glm(Outcome ~ Glucose + Age, 
              data=data_cleaned, family=binomial)
AIC(model2)
model3 <- glm(Outcome ~ Glucose + Age + Insulin, 
              data=data_cleaned, family=binomial)
AIC(model3)
```

\textcolor{red}{Pourquoi l'ajout de la variable `Insulin` augmente-t-il l'AIC ?}

\pause
- \textcolor{red}{Il y a déjà la variable `Glucose`.}

## Sélection des prédicteurs

Il faut tenir compte de la **connaissance du domaine**.

L'insuline est l'hormone responsable de la régulation du taux de glycémie (glucose dans le sang).

`Glucose` : la concentration de glucose plasmatique mesurée 2 heures après un test de tolérance au glucose oral.

`Insulin` : l'insuline sérique 2 heures après le début du test, en micro-unités par millilitre (mu U/ml).

\pause

### `Glucose` et `Insulin` dans le processus métabolique

- Chez un individu en bonne santé, une augmentation du niveau de glucose déclenche la libération d'insuline. 

- Mais, en cas de résistance à l'insuline (un précurseur du diabète), cette relation est perturbée.

## Sélection des prédicteurs

### Glycémie (`Glucose`) et Diabète (`Outcome`)

Il existe généralement une forte corrélation positive. 

- Des niveaux élevés de glucose sont souvent indicatifs du diabète, car l'incapacité du corps à utiliser efficacement l'insuline entraîne une élévation du taux de glycémie.

### Insuline (`Insulin`) et Diabète (`Outcome`)

Cette relation peut être plus complexe. 

- Aux premiers stades du diabète de type 2, les niveaux d'insuline peuvent être élevés car le corps essaie de compenser l'augmentation de glycémie. 

- Avec le temps (dans les stades avancés du diabète), le pancréas peut produire moins d'insuline, conduisant à des niveaux d'insuline plus faibles.

## Introduction au nouveau sujet

**Diabète** : Le corps ne peut pas traiter correctement les niveaux de glucose dans le sang. Cela \textcolor{red}{est dû} soit à une \textcolor{red}{production insuffisante d'insuline par le pancréas} (diabète de type 1) soit à une \textcolor{red}{utilisation inefficace de l'insuline produite} (diabète de type 2 et cas de "Pima Indian Diabetes").

![Confusion dans la relation](Slide-images\confounder.PNG){width=45%, height=45%}

# Confondeur

Un confondeur (ou facteur de confusion) est une variable qui influence à la fois la réponse et le prédicteur. 

Ce facteur peut conduire à une interprétation trompeuse de la relation entre les variables étudiées car il affecte le résultat, mais il ne s'agit pas de la principale variable d'intérêt.

\pause

![La vente de la glace a-t-elle un impact sur une attaque de requin ?](Slide-images\icecreamshark.png){width=35%, height=35%}

## Confondeur

Sans tenir compte de l'augmentation de la température (confondeur), il peut y avoir une association fallacieuse.

![Confondeur dans la relation](Slide-images\Confounding-Variable.jpg){width=55%, height=55%}

## D'autre exemples dans la base de données

**Indice de Masse Corporelle (IMC)** peut être influencé par des facteurs de mode de vie. 

- Un IMC élevé pourrait suggérer un mode de vie incluant moins d'activité physique ou un régime alimentaire pouvant contribuer à la prise de poids, deux facteurs de risque du diabète.
\pause

**Âge** est un facteur connu du risque de diabète. 

- Un âge plus avancé est associé à un risque accru de diabète de type 2, à cause des changements dans le métabolisme et éventuellement de mode de vie au fil du temps.
\pause

**Fonction du Pedigree du Diabète** (ou prédisposition génétique au diabète) prend en compte l'histoire du diabète chez les proches et la relation génétique de ces proches avec le sujet. 

## Résumé

Il est crucial de toujours inclure les confondeurs connus dans le modèle (`BMI`, `Age` et `DiabetesPedigreeFunction`).

Mais, il faut être prudent ...

![Rappel concernant les confondeurs](Slide-images\confounding_variables.png){width=55%, height=55%}

## Erreurs d'identification des confondeurs

Ajuster trop de variables qui ne sont pas des confondeurs peut entraîner un **surajustement**, obscurcissant les vraies associations ou créant de fausses associations.

\pause

Attention à la **collinéarité**, où deux variables prédictives ou plus sont fortement corrélées. Ajuster l'une peut inadvertamment ajuster les autres, conduisant à des résultats trompeurs.

\pause

Il est important de **différencier un confondeur d'un modificateur d'effet** (interaction). 

- Un modificateur d'effet change la direction ou la force de l'association entre l'exposition et le résultat selon ses niveaux.

- Un confondeur est une influence externe à contrôler.

# Travaux pratiques

Continuez à travailler avec la base de données "Pima Indian Diabetes".

Avec `Outcome` comme variable dépendante, utilisez le reste des paramètres comme variables indépendantes pour créer un modèle de régression logistique.

Parmi les variables indépendantes, identifiez des confondeurs possibles et ajustez-les.

Employez les méthodes de sélection progressive et régressive.

Comparez différents modèles avec l'AIC et le BIC.

Quelles variables apportent une contribution importante au modèle (sont des bons prédicteurs pour la réponse `Outcome`) ?